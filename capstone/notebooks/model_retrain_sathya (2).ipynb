{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojIh5IqHNY4s",
    "outputId": "6b4114a0-a5f6-4088-a10e-dcee5ff0b3a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mysql-connector-python\n",
      "  Downloading mysql_connector_python-8.0.28-cp37-cp37m-manylinux1_x86_64.whl (37.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 37.6 MB 1.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from mysql-connector-python) (3.17.3)\n",
      "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.0.0->mysql-connector-python) (1.15.0)\n",
      "Installing collected packages: mysql-connector-python\n",
      "Successfully installed mysql-connector-python-8.0.28\n",
      "Collecting PyMySQL\n",
      "  Downloading PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 1.6 MB/s \n",
      "\u001b[?25hInstalling collected packages: PyMySQL\n",
      "Successfully installed PyMySQL-1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install mysql-connector-python\n",
    "!pip install PyMySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "P7MbouzhNY4x"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pickle\n",
    "import mysql.connector as MySQL \n",
    "import pymysql\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fb6E9Sa6NY4y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HarshR-MBP_Windows\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score,KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier, AdaBoostClassifier, StackingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from collections import Counter\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import fbeta_score, f1_score,precision_score, recall_score,accuracy_score, roc_curve, auc\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split,RandomizedSearchCV\n",
    "from numpy import float64, int64, number\n",
    "from datetime import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WuZQ5489NY4z"
   },
   "outputs": [],
   "source": [
    "# Supress Warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MLyG8QB1NY40"
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "X9trWYEoNY40"
   },
   "outputs": [],
   "source": [
    "# host_name = \"localhost\"\n",
    "# username = 'root'\n",
    "# password = 'root' \n",
    "# db = \"capstone\"\n",
    "# auth_plugin = 'mysql_native_password'\n",
    "# connection = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5bsQqUX2NY41"
   },
   "outputs": [],
   "source": [
    "# # DB connection\n",
    "# def connect_to_db(host_name, username, password, auth_plugin):\n",
    "#     try:\n",
    "#         connection = MySQL.connect(host=host_name, user = username, password = password, auth_plugin=auth_plugin)\n",
    "#         # preparing a cursor object\n",
    "#         cursorObject = connection.cursor()\n",
    "#         query = \"SELECT Serial_number,document_id,URL,Credibility_rating, ad_count,ad_max_size,css_definitions,page_rank,bitly_clicks,bitly_referrers,tweets,delicious_bookmarks,fb_clicks,fb_comments,fb_likes,fb_shares,fb_total,alexa_linksin,alexa_rank,commas,dots,exclamations,questions,spelling_errors,text_complexity,smog,category,JJ,NN,DT,VB,RB,num_ne,sum_ne,document_url_y,X1,X2,X3,X4,X5,X9,Total,Leik,Eijk,Tastle,Leik_3_4_6,correction,resp_HNC,Controversial,troia_label FROM WEB_RAW_DATA\"\n",
    "#         df_raw = pd.read_sql(query,con=connection)\n",
    "#         # disconnecting from server\n",
    "#         connection.close()\n",
    "#     except MySQL.errorcode as err:\n",
    "#         if err.errno == errorcode.ER_TABLE_EXISTS_ERROR:\n",
    "#             print(\"already exists.\")\n",
    "#         else:\n",
    "#             print(err.msg)\n",
    "#         else:\n",
    "#             print('Connected!')\n",
    "#     return df_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "aKecomSFNY43"
   },
   "outputs": [],
   "source": [
    "# df_raw = connect_to_db(host_name, username, password, auth_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 432
    },
    "id": "J0oQ7SLmNY43",
    "outputId": "4a827c28-29af-4e91-a148-216ddad60208"
   },
   "outputs": [],
   "source": [
    "connection = pymysql.connect(\n",
    "  host =\"localhost\",\n",
    "  user =\"root\",\n",
    "  passwd =\"root\",\n",
    "  database = \"capstone\"\n",
    ")\n",
    "# preparing a cursor object\n",
    "cursorObject = connection.cursor()\n",
    "  \n",
    "query = \"SELECT Serial_number,document_id,URL,Credibility_rating, ad_count,ad_max_size,css_definitions,page_rank,bitly_clicks,bitly_referrers,tweets,delicious_bookmarks,fb_clicks,fb_comments,fb_likes,fb_shares,fb_total,alexa_linksin,alexa_rank,commas,dots,exclamations,questions,spelling_errors,text_complexity,smog,category,JJ,NN,DT,VB,RB,num_ne,sum_ne,document_url_y,X1,X2,X3,X4,X5,X9,Total,Leik,Eijk,Tastle,Leik_3_4_6,correction,resp_HNC,Controversial,troia_label FROM WEB_RAW_DATA\"\n",
    "cursorObject.execute(query)\n",
    "columns = [col[0] for col in cursorObject.description]\n",
    "records = cursorObject.fetchall()\n",
    "   \n",
    "# disconnecting from server\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QvqwCordNY45"
   },
   "outputs": [],
   "source": [
    "df_raw = pd.DataFrame(data=records,columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "WyNmE_HmNY45"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial_number</th>\n",
       "      <th>document_id</th>\n",
       "      <th>URL</th>\n",
       "      <th>Credibility_rating</th>\n",
       "      <th>ad_count</th>\n",
       "      <th>ad_max_size</th>\n",
       "      <th>css_definitions</th>\n",
       "      <th>page_rank</th>\n",
       "      <th>bitly_clicks</th>\n",
       "      <th>bitly_referrers</th>\n",
       "      <th>...</th>\n",
       "      <th>X9</th>\n",
       "      <th>Total</th>\n",
       "      <th>Leik</th>\n",
       "      <th>Eijk</th>\n",
       "      <th>Tastle</th>\n",
       "      <th>Leik_3_4_6</th>\n",
       "      <th>correction</th>\n",
       "      <th>resp_HNC</th>\n",
       "      <th>Controversial</th>\n",
       "      <th>troia_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2199424.0</td>\n",
       "      <td>http://unemployment.ohio.gov/</td>\n",
       "      <td>3.714285714285714</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>106.000000000000000</td>\n",
       "      <td>6.000000000000000</td>\n",
       "      <td>9.000000000000000</td>\n",
       "      <td>5.000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>7.000000000000000</td>\n",
       "      <td>0.571428571000000</td>\n",
       "      <td>0.357142857000000</td>\n",
       "      <td>0.613196274000000</td>\n",
       "      <td>0.542857143000000</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>2</td>\n",
       "      <td>U</td>\n",
       "      <td>3.000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2199427.0</td>\n",
       "      <td>http://www.law.cornell.edu/wex/unemployment_co...</td>\n",
       "      <td>4.428571428571429</td>\n",
       "      <td>4.000000000000000</td>\n",
       "      <td>75000.000000000000000</td>\n",
       "      <td>1824.000000000000000</td>\n",
       "      <td>5.000000000000000</td>\n",
       "      <td>12.000000000000000</td>\n",
       "      <td>1.000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>7.000000000000000</td>\n",
       "      <td>0.714285714000000</td>\n",
       "      <td>0.714285714000000</td>\n",
       "      <td>0.735143276000000</td>\n",
       "      <td>0.600000000000000</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>5.000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2547110.0</td>\n",
       "      <td>http://kiem-tv.com/?q=node/4395</td>\n",
       "      <td>4.000000000000000</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>18.000000000000000</td>\n",
       "      <td>2.000000000000000</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>...</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>7.000000000000000</td>\n",
       "      <td>0.714285714000000</td>\n",
       "      <td>0.571428571000000</td>\n",
       "      <td>0.762835715000000</td>\n",
       "      <td>0.657142857000000</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>2</td>\n",
       "      <td>U</td>\n",
       "      <td>4.000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2547112.0</td>\n",
       "      <td>http://www.sciencedaily.com/releases/2012/09/1...</td>\n",
       "      <td>4.833333333333333</td>\n",
       "      <td>9.000000000000000</td>\n",
       "      <td>75000.000000000000000</td>\n",
       "      <td>383.000000000000000</td>\n",
       "      <td>3.000000000000000</td>\n",
       "      <td>45.000000000000000</td>\n",
       "      <td>9.000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>6.000000000000000</td>\n",
       "      <td>0.916666667000000</td>\n",
       "      <td>0.916666667000000</td>\n",
       "      <td>0.892660382000000</td>\n",
       "      <td>0.866666667000000</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>5.000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2547113.0</td>\n",
       "      <td>http://articles.timesofindia.indiatimes.com/20...</td>\n",
       "      <td>3.888888888888889</td>\n",
       "      <td>2.000000000000000</td>\n",
       "      <td>75000.000000000000000</td>\n",
       "      <td>599.000000000000000</td>\n",
       "      <td>3.000000000000000</td>\n",
       "      <td>3.000000000000000</td>\n",
       "      <td>3.000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>9.000000000000000</td>\n",
       "      <td>0.722222222000000</td>\n",
       "      <td>0.611111111000000</td>\n",
       "      <td>0.756750140000000</td>\n",
       "      <td>0.688888889000000</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>2</td>\n",
       "      <td>U</td>\n",
       "      <td>4.000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2201749.0</td>\n",
       "      <td>http://www.ofspirit.com/brucefife1.htm</td>\n",
       "      <td>3.875000000000000</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>1.000000000000000</td>\n",
       "      <td>10.000000000000000</td>\n",
       "      <td>5.000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>8.000000000000000</td>\n",
       "      <td>0.812500000000000</td>\n",
       "      <td>0.750000000000000</td>\n",
       "      <td>0.822781986000000</td>\n",
       "      <td>0.800000000000000</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>2</td>\n",
       "      <td>U</td>\n",
       "      <td>1.000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2201753.0</td>\n",
       "      <td>http://www.ashtarcommandcrew.net/forum/topics/...</td>\n",
       "      <td>2.750000000000000</td>\n",
       "      <td>16.000000000000000</td>\n",
       "      <td>96000.000000000000000</td>\n",
       "      <td>1850.000000000000000</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>...</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>8.000000000000000</td>\n",
       "      <td>0.375000000000000</td>\n",
       "      <td>-0.048611111000000</td>\n",
       "      <td>0.314413828000000</td>\n",
       "      <td>0.400000000000000</td>\n",
       "      <td>-1.000000000000000</td>\n",
       "      <td>C</td>\n",
       "      <td>U</td>\n",
       "      <td>1.000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2201756.0</td>\n",
       "      <td>http://www.mindbodygreen.com/0-4348/5-Ways-to-...</td>\n",
       "      <td>4.250000000000000</td>\n",
       "      <td>13.000000000000000</td>\n",
       "      <td>75000.000000000000000</td>\n",
       "      <td>524.000000000000000</td>\n",
       "      <td>1.000000000000000</td>\n",
       "      <td>335.000000000000000</td>\n",
       "      <td>38.000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>4.000000000000000</td>\n",
       "      <td>0.625000000000000</td>\n",
       "      <td>0.625000000000000</td>\n",
       "      <td>0.691800413000000</td>\n",
       "      <td>0.500000000000000</td>\n",
       "      <td>-1.000000000000000</td>\n",
       "      <td>2</td>\n",
       "      <td>U</td>\n",
       "      <td>1.000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2214309.0</td>\n",
       "      <td>http://www.co-optimus.com/review/1158/page/1/g...</td>\n",
       "      <td>4.428571428571429</td>\n",
       "      <td>4.000000000000000</td>\n",
       "      <td>75000.000000000000000</td>\n",
       "      <td>483.000000000000000</td>\n",
       "      <td>2.000000000000000</td>\n",
       "      <td>18.000000000000000</td>\n",
       "      <td>2.000000000000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>7.000000000000000</td>\n",
       "      <td>0.714285714000000</td>\n",
       "      <td>0.714285714000000</td>\n",
       "      <td>0.735143276000000</td>\n",
       "      <td>0.600000000000000</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>3</td>\n",
       "      <td>U</td>\n",
       "      <td>4.000000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2569345.0</td>\n",
       "      <td>http://katieholmes.com/</td>\n",
       "      <td>3.400000000000000</td>\n",
       "      <td>9.000000000000000</td>\n",
       "      <td>75000.000000000000000</td>\n",
       "      <td>35.000000000000000</td>\n",
       "      <td>4.000000000000000</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>...</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>5.000000000000000</td>\n",
       "      <td>0.800000000000000</td>\n",
       "      <td>0.800000000000000</td>\n",
       "      <td>0.815012042000000</td>\n",
       "      <td>0.840000000000000</td>\n",
       "      <td>0E-15</td>\n",
       "      <td>2</td>\n",
       "      <td>U</td>\n",
       "      <td>3.000000000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial_number  document_id  \\\n",
       "0              1    2199424.0   \n",
       "1              2    2199427.0   \n",
       "2              3    2547110.0   \n",
       "3              4    2547112.0   \n",
       "4              5    2547113.0   \n",
       "5              6    2201749.0   \n",
       "6              7    2201753.0   \n",
       "7              8    2201756.0   \n",
       "8              9    2214309.0   \n",
       "9             10    2569345.0   \n",
       "\n",
       "                                                 URL Credibility_rating  \\\n",
       "0                      http://unemployment.ohio.gov/  3.714285714285714   \n",
       "1  http://www.law.cornell.edu/wex/unemployment_co...  4.428571428571429   \n",
       "2                    http://kiem-tv.com/?q=node/4395  4.000000000000000   \n",
       "3  http://www.sciencedaily.com/releases/2012/09/1...  4.833333333333333   \n",
       "4  http://articles.timesofindia.indiatimes.com/20...  3.888888888888889   \n",
       "5             http://www.ofspirit.com/brucefife1.htm  3.875000000000000   \n",
       "6  http://www.ashtarcommandcrew.net/forum/topics/...  2.750000000000000   \n",
       "7  http://www.mindbodygreen.com/0-4348/5-Ways-to-...  4.250000000000000   \n",
       "8  http://www.co-optimus.com/review/1158/page/1/g...  4.428571428571429   \n",
       "9                            http://katieholmes.com/  3.400000000000000   \n",
       "\n",
       "             ad_count            ad_max_size       css_definitions  \\\n",
       "0               0E-15                  0E-15   106.000000000000000   \n",
       "1   4.000000000000000  75000.000000000000000  1824.000000000000000   \n",
       "2               0E-15                  0E-15    18.000000000000000   \n",
       "3   9.000000000000000  75000.000000000000000   383.000000000000000   \n",
       "4   2.000000000000000  75000.000000000000000   599.000000000000000   \n",
       "5               0E-15                  0E-15                 0E-15   \n",
       "6  16.000000000000000  96000.000000000000000  1850.000000000000000   \n",
       "7  13.000000000000000  75000.000000000000000   524.000000000000000   \n",
       "8   4.000000000000000  75000.000000000000000   483.000000000000000   \n",
       "9   9.000000000000000  75000.000000000000000    35.000000000000000   \n",
       "\n",
       "           page_rank         bitly_clicks     bitly_referrers  ...     X9  \\\n",
       "0  6.000000000000000    9.000000000000000   5.000000000000000  ...  0E-15   \n",
       "1  5.000000000000000   12.000000000000000   1.000000000000000  ...  0E-15   \n",
       "2  2.000000000000000                0E-15               0E-15  ...  0E-15   \n",
       "3  3.000000000000000   45.000000000000000   9.000000000000000  ...  0E-15   \n",
       "4  3.000000000000000    3.000000000000000   3.000000000000000  ...  0E-15   \n",
       "5  1.000000000000000   10.000000000000000   5.000000000000000  ...  0E-15   \n",
       "6              0E-15                0E-15               0E-15  ...  0E-15   \n",
       "7  1.000000000000000  335.000000000000000  38.000000000000000  ...  0E-15   \n",
       "8  2.000000000000000   18.000000000000000   2.000000000000000  ...  0E-15   \n",
       "9  4.000000000000000                0E-15               0E-15  ...  0E-15   \n",
       "\n",
       "               Total               Leik                Eijk  \\\n",
       "0  7.000000000000000  0.571428571000000   0.357142857000000   \n",
       "1  7.000000000000000  0.714285714000000   0.714285714000000   \n",
       "2  7.000000000000000  0.714285714000000   0.571428571000000   \n",
       "3  6.000000000000000  0.916666667000000   0.916666667000000   \n",
       "4  9.000000000000000  0.722222222000000   0.611111111000000   \n",
       "5  8.000000000000000  0.812500000000000   0.750000000000000   \n",
       "6  8.000000000000000  0.375000000000000  -0.048611111000000   \n",
       "7  4.000000000000000  0.625000000000000   0.625000000000000   \n",
       "8  7.000000000000000  0.714285714000000   0.714285714000000   \n",
       "9  5.000000000000000  0.800000000000000   0.800000000000000   \n",
       "\n",
       "              Tastle         Leik_3_4_6          correction resp_HNC  \\\n",
       "0  0.613196274000000  0.542857143000000               0E-15        2   \n",
       "1  0.735143276000000  0.600000000000000               0E-15        3   \n",
       "2  0.762835715000000  0.657142857000000               0E-15        2   \n",
       "3  0.892660382000000  0.866666667000000               0E-15        3   \n",
       "4  0.756750140000000  0.688888889000000               0E-15        2   \n",
       "5  0.822781986000000  0.800000000000000               0E-15        2   \n",
       "6  0.314413828000000  0.400000000000000  -1.000000000000000        C   \n",
       "7  0.691800413000000  0.500000000000000  -1.000000000000000        2   \n",
       "8  0.735143276000000  0.600000000000000               0E-15        3   \n",
       "9  0.815012042000000  0.840000000000000               0E-15        2   \n",
       "\n",
       "  Controversial        troia_label  \n",
       "0             U  3.000000000000000  \n",
       "1             U  5.000000000000000  \n",
       "2             U  4.000000000000000  \n",
       "3             U  5.000000000000000  \n",
       "4             U  4.000000000000000  \n",
       "5             U  1.000000000000000  \n",
       "6             U  1.000000000000000  \n",
       "7             U  1.000000000000000  \n",
       "8             U  4.000000000000000  \n",
       "9             U  3.000000000000000  \n",
       "\n",
       "[10 rows x 50 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tJfvvZhyNY46"
   },
   "outputs": [],
   "source": [
    "def regression_retrain():\n",
    "  #removing the obvious column not going to used in the model\n",
    "    cols_not_required = ['Serial_number','document_id','URL','Catrgory']\n",
    "    # cols_not_required = ['document_id','URL']\n",
    "    # make a copy of the raw data\n",
    "    df_main = df_raw.copy()\n",
    "    df_main.drop(cols_not_required,axis=1,inplace=True)\n",
    "    \n",
    "    #getting on the popular domain as in the list below\n",
    "    array = ['com', 'org', 'gov', 'edu','net','uk','au','ca','in']\n",
    "    df2 = df_main.loc[df_main['document_url_y'].isin(array)]\n",
    "    \n",
    "    # Dropping the missing values.\n",
    "    df2=df2.fillna(0)\n",
    "    # df2 = df2.drop(['category','ad_count', 'ad_max_size', 'css_definitions', 'page_rank',\n",
    "    #    'bitly_clicks', 'bitly_referrers', 'tweets', 'delicious_bookmarks',\n",
    "    #    'fb_clicks', 'fb_comments', 'fb_likes', 'fb_shares', 'fb_total',\n",
    "    #    'alexa_linksin','num_ne', 'sum_ne','X1', 'X2', 'X3', 'X4', 'X5', 'X9', 'Total',\n",
    "    #    'Leik', 'Eijk', 'Tastle','Leik 3 4 6', 'correction', 'resp_HNC', 'Controversial', 'troia_label'],axis=1)\n",
    "\n",
    "    # Using label encoder to convert document_url_y into dummy\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df2.document_url_y = le.fit_transform(df2.document_url_y)\n",
    "    df1=df2\n",
    "\n",
    "    # defining x and y\n",
    "    y = df1[\"Credibility_rating\"]\n",
    "    X = df1.drop(\"Credibility_rating\",axis=1) \n",
    "\n",
    "    # Splitting the dataset\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=0)\n",
    "    \n",
    "    # performing preprocessing part\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    #reading previous metrics \n",
    "\n",
    "    path_of_file = 'regression_performance.json'\n",
    "    # checking if size of file is 0\n",
    "    if os.path.getsize(path_of_file) == 0:\n",
    "        return \"File is empty, train the inital model\"\n",
    "    else:\n",
    "        #loading the json \n",
    "        with open('regression_performance.json', 'r') as f:\n",
    "            previous_perf = json.load(f)\n",
    "            if(len(previous_perf)!=0):\n",
    "                previous_r2_score = previous_perf['output'][len(previous_perf['output'])-1]['test_r2_score']\n",
    "            else :\n",
    "                return \"train the inital model Or Check the Json\"\n",
    "        f.close()\n",
    "\n",
    "    # Random Forest model\n",
    "    rf =RandomForestClassifier(n_estimators=250,random_state=1)\n",
    "    rf_model = rf.fit(X_train,y_train)\n",
    "    #y_train_pred = rf_model.predict(X_train)\n",
    "    y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "    # train r2_score = r2_score(y_train,y_train_pred)\n",
    "    test_r2_score = r2_score(y_test,y_test_pred)\n",
    "\n",
    "    perform_metrics ={'test_r2_score':test_r2_score}\n",
    "\n",
    "    # compare old and new accuracy and then pickle the new model to use by the application, \n",
    "    # if retrained model gives better performance\n",
    "    if test_r2_score>previous_r2_score:\n",
    "        with open(\"./models/le_x_docURL.pkl\",'wb') as file:\n",
    "            pickle.dump(le_x_docURL,file)\n",
    "        file.close()\n",
    "        with open(\"./models/le_y.pkl\",'wb') as file:\n",
    "            pickle.dump(le_y,file)\n",
    "        file.close()\n",
    "        with open(\"./models/standardscaler.pkl\",'wb') as file:\n",
    "            pickle.dump(sc,file)\n",
    "        file.close()\n",
    "        with open(\"./models/category_model.pkl\",'wb') as file:\n",
    "            pickle.dump(rf_model,file)\n",
    "        file.close()\n",
    "        # storing the data in JSON format\n",
    "        previous_perf['output'].append({\"CapturedTime\" : datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"),\n",
    "                                        \"test_r2_score\":test_r2_score}\n",
    "                                       )\n",
    "        # saving the upgraded accuracy along with other metrics and old values in Json\n",
    "        with open(\"regression_performance.json\", \"w\") as outfile:\n",
    "            json.dump(previous_perf, outfile)\n",
    "        outfile.close()\n",
    "\n",
    "    return previous_perf['output'][len(previous_perf['output'])-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "IprxEpa5NY46"
   },
   "outputs": [],
   "source": [
    "def classification_retrain():\n",
    "    \n",
    "    #removing the obvious column not going to used in the model\n",
    "    cols_not_required = ['Serial_number','document_id','URL','Credibility_rating']\n",
    "    \n",
    "    # make a copy of the raw data\n",
    "    df_main = df_raw.copy()\n",
    "    df_main.drop(cols_not_required,axis=1,inplace=True)\n",
    "    \n",
    "    #getting on the popular domain as in the list below\n",
    "    array = ['com', 'org', 'gov', 'edu','net','uk','au','ca','in']\n",
    "    df2 = df_main.loc[df_main['document_url_y'].isin(array)]\n",
    "    \n",
    "    #filling all null category as 'unknown'\n",
    "    df2[\"category\"].fillna(\"Unknown\", inplace = True)\n",
    "    \n",
    "    # Dropping the missing values.\n",
    "    df2=df2.fillna(0)\n",
    "    \n",
    "    # Categorical features has to be converted into integer values for the model to process(one hot encoding).\n",
    "    y_data = df2[\"category\"]\n",
    "    X_data = df2.drop(['category','ad_count', 'ad_max_size', 'css_definitions', 'page_rank',\n",
    "       'bitly_clicks', 'bitly_referrers', 'tweets', 'delicious_bookmarks',\n",
    "       'fb_clicks', 'fb_comments', 'fb_likes', 'fb_shares', 'fb_total',\n",
    "       'alexa_linksin','num_ne', 'sum_ne','X1', 'X2', 'X3', 'X4', 'X5', 'X9', 'Total',\n",
    "       'Leik', 'Eijk', 'Tastle','Leik_3_4_6', 'correction', 'resp_HNC', 'Controversial', 'troia_label'],axis=1)\n",
    "    \n",
    "    # select categorical features\n",
    "    cat_x = X_data.select_dtypes(include=['object']).columns\n",
    "    \n",
    "    le_x_docURL = preprocessing.LabelEncoder()\n",
    "    X_data.document_url_y = le_x_docURL.fit_transform(X_data.document_url_y)\n",
    "    \n",
    "    # label encode the target variable\n",
    "    le_y = preprocessing.LabelEncoder()\n",
    "    y = le_y.fit_transform(y_data)\n",
    "\n",
    "    # Splitting the dataset\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X_data,y,test_size=0.3,random_state=0)\n",
    "    \n",
    "    # performing preprocessing part\n",
    "    sc = StandardScaler()\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "    \n",
    "    #reading previous metrics \n",
    "\n",
    "    path_of_file = 'classification_performance.json'\n",
    "    # checking if size of file is 0\n",
    "    if os.path.getsize(path_of_file) == 0:\n",
    "        return \"File is empty, train the inital model\"\n",
    "    else:\n",
    "        #loading the json \n",
    "        with open('classification_performance.json', 'r') as f:\n",
    "            previous_perf = json.load(f)\n",
    "            if(len(previous_perf)!=0):\n",
    "                previous_accuracy=previous_perf['output'][len(previous_perf['output'])-1]['Accuracy']\n",
    "            else :\n",
    "                return \"train the inital model Or Check the Json\"\n",
    "        f.close()\n",
    "      \n",
    "    # Random Forest model\n",
    "    rf =RandomForestClassifier()\n",
    "    rf_model = rf.fit(X_train,y_train)\n",
    "    #y_train_pred = rf_model.predict(X_train)\n",
    "    y_test_pred = rf_model.predict(X_test)\n",
    "\n",
    "    precision = precision_score(y_test,y_test_pred, average='weighted')\n",
    "    recall = recall_score(y_test,y_test_pred, average='weighted')\n",
    "    accuracy = accuracy_score(y_test,y_test_pred)\n",
    "    f1 = f1_score(y_test,y_test_pred, average='weighted')\n",
    "    perform_metrics ={\"Accuracy\" : accuracy,\"Recall\" : recall,\n",
    "            \"Precision\" : precision,\"F1-score\" : f1}\n",
    "    \n",
    "    # compare old and new accuracy and then pickle the new model to use by the application, \n",
    "    # if retrained model gives better performance\n",
    "    if accuracy>previous_accuracy:\n",
    "        with open(\"./models/le_x_docURL.pkl\",'wb') as file:\n",
    "            pickle.dump(le_x_docURL,file)\n",
    "        file.close()\n",
    "        with open(\"./models/le_y.pkl\",'wb') as file:\n",
    "            pickle.dump(le_y,file)\n",
    "        file.close()\n",
    "        with open(\"./models/standardscaler.pkl\",'wb') as file:\n",
    "            pickle.dump(sc,file)\n",
    "        file.close()\n",
    "        with open(\"./models/category_model.pkl\",'wb') as file:\n",
    "            pickle.dump(rf_model,file)\n",
    "        file.close()\n",
    "        # storing the data in JSON format\n",
    "        previous_perf['output'].append({\"CapturedTime\" : datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\"),\n",
    "                                        \"Accuracy\" : accuracy,\n",
    "                                        \"Recall\" : recall,\n",
    "                                        \"Precision\" : precision,\n",
    "                                        \"F1-score\" : f1}\n",
    "                                      )\n",
    "        #saving the upgraded accuracy along with other metrics and old values in Json\n",
    "        with open(\"classification_performance.json\", \"w\") as outfile:\n",
    "            json.dump(previous_perf, outfile)\n",
    "        outfile.close()\n",
    "     \n",
    "    \n",
    "    return previous_perf['output'][len(previous_perf['output'])-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 304
    },
    "id": "DzcoNUqANY47",
    "outputId": "392b0507-33f8-4574-a1e8-d7ca30a30693"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-698324c2e4d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassification_retrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#before running this, run the primary training of the model for the same json (classification_performance) for initial accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-51080afc37e6>\u001b[0m in \u001b[0;36mclassification_retrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# make a copy of the raw data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdf_main\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_raw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mdf_main\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcols_not_required\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_raw' is not defined"
     ]
    }
   ],
   "source": [
    "classification_retrain()\n",
    "#before running this, run the primary training of the model for the same json (classification_performance) for initial accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "10oWDsqBNY48"
   },
   "outputs": [],
   "source": [
    "regression_retrain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wjL_HqgkNY48"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xqrZq-a1NY48"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "model_retrain_sathya.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
